# -*- coding: utf-8 -*-
"""Logistic Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1imCfb2AgX7x0dAWQvoRsiJR-vYuVe9sq
"""

# Commented out IPython magic to ensure Python compatibility.
#import required libraries
#for data import and basic oprtaion

# The purpose of this library is to create the dataset or dataframe
import pandas as pd

# For numerical operation and other functions
import numpy as np

#for visulization and plotting
import matplotlib.pyplot as plt
import seaborn as sns

#to view the plots in the jupyter notebook inline
# %matplotlib inline

#load the dataset or reading the dataset 
data = pd.read_csv(r"/content/framingham.csv") # the dataset will be read out in read only mode.

data # It display the entire dataset details

#check top 10 records
data.head(10) # it will display top 10 records

data['BMI'].fillna(data.groupby('glucose')['BMI'].transform('median'), inplace = True)

data['BPMeds'].fillna(data.groupby('totChol')['BPMeds'].transform('median'), inplace = True)

data['education'].fillna(data.groupby('cigsPerDay')['education'].transform('median'), inplace = True)

data

data['glucose'].fillna(data.groupby('totChol')['glucose'].transform('median'), inplace = True)

data

data.isna().sum()

data['heartRate'].fillna(data.groupby('BMI')['heartRate'].transform('median'), inplace = True)

data['BMI'].fillna(data.groupby('cigsPerDay')['BMI'].transform('median'), inplace = True)

data['cigsPerDay'].fillna(data.groupby('totChol')['cigsPerDay'].transform('median'), inplace = True)

data['cigsPerDay'].fillna(data.groupby('education')['cigsPerDay'].transform('median'), inplace = True)

data['glucose'].fillna(data.groupby('diabetes')['glucose'].transform('median'), inplace = True)

data['totChol'].fillna(data.groupby('diaBP')['totChol'].transform('median'), inplace = True)

data['BPMeds'].fillna(data.groupby('age')['BPMeds'].transform('median'), inplace = True)

data['education'].fillna(data.groupby('sysBP')['education'].transform('median'), inplace = True)

data.isna().sum()

# we are Choosing dependent and independent variables

#split dataset in features (Independent) and target (Dependent) variable
ind_var = ['age', 'BMI']
X = data[ind_var] # Features or independent variables

y = data.heartRate # Target variable or dependent variable or response variable

X

y

# Next step, we need to classify the data into training and testing dataset

#to split the dataset into train and test
from sklearn.model_selection import train_test_split

#split the dataset in train and test
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.18,random_state=0)

X_train.shape #It will display the size of the training data in terms of X-axis
# total no. of rows, columns

X_test.shape #It will display the size of the test data in terms of X-axis
# total no. of rows, columns

y_test.shape

"""# So far we have the followings:
# 1. Prepare the data
# 2. Training and Testing Data
"""

X_train

y_train

# Model Development

# Our Next step would be to build the model by training data
# We are using logistic regression to build the model

#to apply logistic regresison
from sklearn.linear_model import LogisticRegression

# instantiate the model using the default parameters
lr = LogisticRegression()

# fit the model with data
lr.fit(X_train,y_train) #we are fitting the model as per or towards training dataset

"""# So far we have the followings:
# 1. Prepare the data
# 2. Training and Testing Data
# 3. Build the model
"""

# we need to predict the model using testing dataset

#prediction on test dataset
y_pred=lr.predict(X_test) # X_test contains the details of testing dataset w.r.t independent variables

y_pred # It contains the predicted values followed by Testing data

y_test # It contains the actual values

'''
y_test        y_pred

1             1     ------> (True Positive)
1             0 (No)    -------> (False Negative)
0             0 ---------->          (True Negative)
1             1 (No)
0             0
0             1 ---------->           (False Positive)

There is no difference between y_test (actual) and y_pred (predicted) values.
60%

'''

# So far we have the followings:
# 1. Prepare the data
# 2. Training and Testing Data
# 3. Build the model
# 4. Testing the model
# 5. Next-Model Evaluation or Performance of the Model

"""# So far we have the followings:
# 1. Prepare the data
# 2. Training and Testing Data
# 3. Build the model
# 4. Testing the model
# 5. Next-Model Evaluation or Performance of the Model
"""

#to create the confusion matrix
from sklearn import metrics

#confusion matrix and it returns the details in array form
con_mat = metrics.confusion_matrix(y_test, y_pred)

# we are comparing actual values and prediction values from testing dataset
print(con_mat)

# seaborn - is a library for graph purpose like matplotlib
# it is also used to display some standard graph which are following by python libraries
# to represent you data in graphical way
import seaborn as vsk_sn # vsk_sn it is the only aliasing variable

# crosstab is a method which is a part of pandas libray
# This method is used to compute a simple cross-tabulation of two (or more) factors. 
# By default, computes a frequency table of the factors unless an array of values 
# and an aggregation function are passed.

c_m = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])

#heatmap is graph in form of map in 2x2 matrix form
vsk_sn.heatmap (c_m, annot=True, fmt="", linewidths = 0.30)

# 1(Actual) & 1 (Predicted) = True Positive
# 0(Actual) & 0 (Predicted) = True Negative
# 1(Actual) & 0 (Predicted) = False Negative
# 0(Actual) & 1 (Predicted) = False Positive

#evaluation metrices
# We are measuring the performance of the our built model

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test, y_pred))
print("Recall:",metrics.recall_score(y_test, y_pred))

print('Accuracy: ',metrics.accuracy_score(y_test, y_pred)*100,'%')
print("Precision:" ,metrics.precision_score(y_test, y_pred)*100,'%')
print("Recall:",metrics.recall_score(y_test, y_pred)*100,'%')

# Classification model summary report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

#To predict heartRate
y_pred_new=lr.predict([[90,35]])

y_pred_new